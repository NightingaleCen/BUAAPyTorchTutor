{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验：植物识别"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在我们读入数据集中的图片时，我们需要对图片进行预处理，使其能够从图像转变为能够被模型读取的数据格式，同时对于训练数据，我们可能想对它们进行[数据增广](https://pytorch.org/vision/stable/transforms.html)来提升训练效果，这些操作都可以通过`torchvision.transforms`来实现。在下面，我们定义了一个针对了训练的`train_transform`，其中包含了数据转换与一些数据增广相关的变换，我们还定义了针对验证和测试的`test_transform`，其中只包含了数据转换的步骤，因为我们不需要在测试时进行数据增广。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "# 下面的代码除了随机将图片裁剪为224x224以外没有使用其他的数据增广\n",
    "# 你可以随意添加自己想使用的数据增广变换\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    (\n",
    "        transforms.PILToTensor(),\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        transforms.RandomResizedCrop(\n",
    "            224, interpolation=transforms.InterpolationMode.BILINEAR\n",
    "        ),\n",
    "####################################################################################\n",
    "#       你可以在这里添加你想要的变换                                                    #\n",
    "#       transforms.xxx(),                                                          #\n",
    "#       transforms.xxx(),                                                          #                             \n",
    "####################################################################################        \n",
    "    )\n",
    ")\n",
    "\n",
    "test_transform = transforms.Compose(\n",
    "    (\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(256, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们需要定义数据集来读取数据，对于训练集和验证集，因为它们的文件结构为主文件夹中包含了对应多个类别的子文件夹。\n",
    "所以我们可以直接使用`torchvision.datasets.ImageFolder`来建立带标签的数据集。但是对于测试集，我们需要通过继承`VisionDataset`类的方法来构建自己的数据集类。在这里，我们建立了`PlantDataset`，它能够读取指定文件夹下的所有图片，并且在被调用时返回经过转换后的数据值以及作为标签的文件名。\n",
    "记得把你在上面定义的变换作为参数传给对应的数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import VisionDataset\n",
    "from typing import Any, Callable, List, Optional, Tuple\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "class PlantDataset(VisionDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        transforms: Optional[Callable] = None,\n",
    "        transform: Optional[Callable] = None,\n",
    "        target_transform: Optional[Callable] = None,\n",
    "    ) -> None:\n",
    "        super().__init__(root, transforms, transform, target_transform)\n",
    "        data_path = Path(self.root)\n",
    "        image_list = list(data_path.glob(\"*.jpg\"))\n",
    "        self.images = [str(i) for i in image_list]\n",
    "\n",
    "    def __getitem__(self, index: int) -> Any:\n",
    "        image_path = self.images[index]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image = self.transforms(image)\n",
    "\n",
    "        label = re.sub(r\"\\D\", \"\", os.path.sep(image_path)[1])  # 这里会把文件后缀给去掉，将文件名保留作为标签返回\n",
    "        return image, int(label)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_path = './10 plants dataset'\n",
    "batch_size = 32 # @param\n",
    "num_workers = 0 # @param 如果你使用的是CPU，建议不要改动\n",
    "torch.manual_seed(42) # @param 为你的pytorch指定一个随机数种子，使得每一次的结果可以被复现\n",
    "\n",
    "train_path = (os.path.join(data_path, 'train'))\n",
    "test_path = (os.path.join(data_path, 'test'))\n",
    "val_path = (os.path.join(data_path, 'val'))\n",
    "\n",
    "train_dataset = ImageFolder(\n",
    "    train_path,\n",
    "    train_transform)\n",
    "val_dataset = ImageFolder(\n",
    "    val_path,\n",
    "    test_transform)\n",
    "test_dataset = PlantDataset(\n",
    "    test_path,\n",
    "    test_transform)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在训练和测试时，PyTorch通过`DataLoader`类来从定义好的dataset中读取每一个batch的数据，在下面我们建立了三个`DataLoader`对象，并指定训练和验证时的batch size为超参数`batch_size`的值。此处我们还指定测试时的batch size为1，你也可以取一个其他值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=True)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=len(val_dataset),\n",
    "    num_workers=num_workers,\n",
    "    shuffle=True)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    num_workers=num_workers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在下面一个单元格中，请你搭建自己的神经网络。具体来说，你需要自定义一个继承自`nn.Module`的类，并在`__init__`方法中定义这个类各层的结构，在`forward`方法中定义网络前向传播的方式（反向传播已经由PyTorch替你安排好了，对此无需担心），如果你对这部分感到有问题，可以参阅PyTorch官方教程[BUILD THE NEURAL NETWORK](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html)或询问助教。考虑到我们在处理的是二维图像问题，你可能还要参阅[二维卷积核(Conv2d)](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html?highlight=conv2d)这一模块的文档，当然你也可以询问ChatGPT，请注意我们在`transforms`中指定图片的宽高为224x224，在计算卷积核大小时不要忘记这一点。\n",
    ">注：你可以像官方教程一样将多个神经网络模块串联在`nn.Sequential()`中，也可以将它们分开定义，并在前向传播时指定传递方式，在搭建复杂的网络时往往后者更为实用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class ExampleNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "####################################################################################\n",
    "#       你可以在这里定义你的神经网络                                                    #\n",
    "#       self.conv1 = nn.(3, 5, 3),                                                 #\n",
    "#       self.relu1 = nn.ReLU(),                                                    #                             \n",
    "#       ...                                                                        #\n",
    "####################################################################################  \n",
    "\n",
    "    def forward(self, x):\n",
    "####################################################################################\n",
    "#       你可以在这里定义你的前向传播                                                    #\n",
    "#       x = self.conv1(x),                                                         #\n",
    "#       logits = self.relu1(x),                                                    #                             \n",
    "#       ...                                                                        #\n",
    "#################################################################################### \n",
    "        return logits\n",
    "    \n",
    "model = ExampleNetwork().to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在下面，我们指定了模型训练的各超参数，我们默认使用带动量的SGD作为优化器，交叉熵损失作为损失函数，你也可以尝试使用Adam等不同的选择，或是指定学习率衰减策略。\n",
    "我们还定义了一些用于评估模型训练效果的指标，如topk准确率，它们有助于我们在训练过程中跟踪模型的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "learning_rate = 1e-3  # @param\n",
    "epochs = 20  # @param\n",
    "warmup_epoches = 2  # @param\n",
    "\n",
    "iters_per_epoch = np.ceil(len(train_dataset) / batch_size)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=1e-4, momentum=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "  \"\"\"Computes and stores the average and current value\"\"\"\n",
    "  def __init__(self, name, fmt=':f'):\n",
    "      self.name = name\n",
    "      self.fmt = fmt\n",
    "      self.reset()\n",
    "\n",
    "  def reset(self):\n",
    "      self.val = 0\n",
    "      self.avg = 0\n",
    "      self.sum = 0\n",
    "      self.count = 0\n",
    "\n",
    "  def update(self, val, n=1):\n",
    "      self.val = val\n",
    "      self.sum += val * n\n",
    "      self.count += n\n",
    "      self.avg = self.sum / self.count\n",
    "\n",
    "  def __str__(self):\n",
    "      fmtstr = '{name} {avg' + self.fmt + '}'\n",
    "      return fmtstr.format(**self.__dict__)\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "  \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "  with torch.no_grad():\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "batch_time = AverageMeter('Time', ':6.3f')\n",
    "data_time = AverageMeter('Data', ':6.3f')\n",
    "losses = AverageMeter('Training loss', ':.4e')\n",
    "top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "top5 = AverageMeter('Acc@5', ':6.2f')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下是模型实际的训练代码，注意在每一次iteration中，loss在何时计算，梯度在何时反向传播（别忘记清空优化器中已有的梯度），权重和学习率（如果你有学习率衰减）在何时进行调整。每经过一个完整的epoch，模型会在验证集上进行一次评估，记录其损失和准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "val_loss_history = []\n",
    "loss_history = []\n",
    "top1_history = []\n",
    "top5_history = []\n",
    "best_loss = 0x7fffffff\n",
    "\n",
    "start = time.time()\n",
    "for i in range(epochs):\n",
    "  for batch, (X, y) in enumerate(train_loader):\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "    data_time.update(time.time() - start)\n",
    "    pred = model(X)\n",
    "    loss = loss_fn(pred, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # scheduler.step()\n",
    "  \n",
    "  batch_time.update(time.time() - start)\n",
    "  start = time.time()\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for batch, (X, y) in enumerate(val_loader):\n",
    "      X = X.to(device)\n",
    "      y = y.to(device)\n",
    "      pred = model(X)\n",
    "      val_loss = loss_fn(pred, y)\n",
    "      if val_loss.item() < best_loss:\n",
    "        best_loss = val_loss.item()\n",
    "        best_epoch = i\n",
    "        best_model = model\n",
    "      acc1, acc5 = accuracy(pred, y, topk=(1, 5))\n",
    "      loss_history.append(loss.item())\n",
    "      val_loss_history.append(val_loss.item())\n",
    "      top1_history.append(acc1[0])\n",
    "      top5_history.append(acc5[0])\n",
    "      losses.update(loss.item(), X.size(0))\n",
    "      top1.update(acc1[0], X.size(0))\n",
    "      top5.update(acc5[0], X.size(0))\n",
    "      \n",
    "  print(f\"Epoch:{i + 1}: {batch_time}, {losses}, Validation loss {val_loss.item():.4e}, {top1}, {top5}, learning rate {optimizer.state_dict()['param_groups'][0]['lr']}\")\n",
    "  losses.reset()\n",
    "  top1.reset()\n",
    "  top5.reset()\n",
    "\n",
    "print(f\"Best Epoch:{best_epoch + 1}, loss: {best_loss}, Acc@1: {top1_history[best_epoch]}, Acc@5: {top5_history[best_epoch]}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练结束之后，我们可以将每一个epoch存储的各项指标在图标上绘制出来，观察它们是怎样变化的。如果你使用tensorboard或wandb，这一过程也可以实时进行。注意执行这个单元格需要你安装了`matplotlib`库，你可以直接执行`pip install matplotlib`来安装（注意安装后可能需要你重启内核并重新训练）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import randint\n",
    "%matplotlib inline\n",
    "plt.plot(np.arange(1, epochs+1), loss_history, label=\"loss\")\n",
    "plt.plot(np.arange(1, epochs+1), val_loss_history, label=\"val_loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "plt.plot(np.arange(1, epochs+1), [i.item() for i in top1_history])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Acc@1\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过将测试集的DataLoader传给下面的函数，我们可以对模型在测试集上进行测试，测试的过程与训练类似，只是不需要更新梯度。`model.eval()`和`with torch.no_grad():`会告诉模型现在正处于测试的状态，注意模型的输出总是一个代表了类别的整数，因此需要构建`IDX_TO_CLASSES`来建立反向的索引，使得我们能从模型输出的数字得到具体的类别名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES_TO_IDX = train_dataset.class_to_idx\n",
    "IDX_TO_CLASSES = {CLASSES_TO_IDX[i]:i for i in train_dataset.classes}\n",
    "\n",
    "\n",
    "def test(model, test_image, name_prefix):\n",
    "    model.eval()\n",
    "    labels = []\n",
    "    image_numbers = []\n",
    "    with torch.no_grad(): # 在测试时，需要禁用梯度的计算\n",
    "        for _, (images, image_number) in enumerate(test_image):\n",
    "            images = images.to(device)\n",
    "            y = model(images)\n",
    "            batch_labels = torch.argmax(y, dim=1) # 取线性层输出最大值的下标作为我们对应的分类下标\n",
    "            labels.append(batch_labels)\n",
    "            image_numbers.append(image_number)\n",
    "    ans = torch.cat(labels, 0).cpu().numpy()\n",
    "    image_numbers = torch.cat(image_numbers, 0).cpu().numpy()\n",
    "    res = {str(image_numbers[i]): IDX_TO_CLASSES[j] for i, j in enumerate(ans)}\n",
    "    print(f\"{name_prefix} model result:\", res)\n",
    "    return res\n",
    "\n",
    "\n",
    "res = test(best_model, test_loader, \"best\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来就可以输出你的模型测试结果了，不要忘记修改文件名为`<学号>-<姓名>.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "filename = \"<学号>-<姓名>\" # 在此处编辑你的文件名\n",
    "with open(f\"{filename}.json\", \"w\") as f:\n",
    "    json.dump(res, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
